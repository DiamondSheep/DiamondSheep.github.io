---
layout: archive
title: "Resume"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

## Education

* B.S. in **Automotive Engineering**, *Hefei University of Technology*, 2015~2019
* M.S. in **Computer Science**, *Hefei University of Technology*, 2020~2023 (expected)

## Research Interesting 

* Machine Learning
* Deep Model Compression and Acceleration
* Low-bit Quantization
* Robotics

## Publications

  * Yan Luo#, **Yangcheng Gao**#, *et al.* "Long-Range Zero-Shot Generative Deep Network Quantization," submitted to *CVPR*, 2023.
    
  * Zhao Zhang, **Yangcheng Gao**, *et al.* "SelectQ: Calibration Data Selection for Post-Training Quantization," submitted to *CVPR*, 2023.
    
  * â€¦, Huan Zheng, **Yangcheng Gao**, *et al.* "MIPI 2022 Challenge on Under-Display Camera Image Restoration: Methods and Results," Mobile Intelligent Photography and Imaging Workshop 2022 (ECCV MIPI), *Tel-Aviv*, Israel, Oct 2022.
    
  * **Yangcheng Gao**, Zhao Zhang, *et al.* "ClusterQ: Semantic Feature Distribution Alignment for Data-Free Quantization," submitted to *IEEE TNNLS*, 2022.
    
  * **Yangcheng Gao**, Zhao Zhang, *et al.* "Towards Feature Distribution Alignment and Diversity Enhancement for Data-Free Quantization," *IEEE ICDM* 2022.
    
  * **Yangcheng Gao**, Zhao Zhang, *et al.* "Fast and Effective Data-Free Deep Neural Network Compression by Dictionary Pair-Driven Reconstruction," submitted to *KAIS*, 2022. 
    
  * **Yangcheng Gao**, Zhao Zhang, *et al.* "Dictionary Pair-based Data-Free Fast Deep Neural Network Compression," *IEEE ICDM* 2021. (Invited for *KAIS* journal publication as **Best-ranked** paper)
  
## Work Experience

  <img src="/images/shlab.png" align='right' width="25%" height="25%"/>

* Spring 2022: [**Shanghai AI Laboratory**](https://www.shlab.org.cn/)  Research Intern

  * Duties included: **Model Quantization Theory Research**
  * Supervisor: Dong Wang
  
## Skills

* Python
* C++
* Machine Learning Tools
  * PyTorch
  * NumPy
  * TensorRT & ncnn (for model deployment)
